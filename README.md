# ğŸ¤– Tá»•ng Há»£p CÃ¡c Dá»± Ãn Machine Learning Trong MÃ´n Há»c "MÃ¡y Há»c Thá»‘ng KÃª"

ğŸ‘‹ ChÃ o má»«ng báº¡n Ä‘áº¿n vá»›i kho lÆ°u trá»¯ cÃ¡c dá»± Ã¡n trong Ä‘á»“ Ã¡n mÃ´n há»c 'MÃ¡y há»c thÃ´ng kÃª". Kho nÃ y chá»©a má»™t loáº¡t cÃ¡c dá»± Ã¡n thá»ƒ hiá»‡n nhá»¯ng ká»¹ nÄƒng vÃ  kiáº¿n thá»©c cá»§a tÃ´i trong lÄ©nh vá»±c há»c mÃ¡y, tá»« xá»­ lÃ½ dá»¯ liá»‡u Ä‘áº¿n xÃ¢y dá»±ng vÃ  Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh phá»©c táº¡p.

## ğŸ“‹ Má»¥c Lá»¥c
1. [ğŸ’³ Dá»± Ã¡n 1: PhÃ¢n loáº¡i Ä‘iá»ƒm tÃ­n dá»¥ng](#-dá»±-Ã¡n-1-phÃ¢n-loáº¡i-Ä‘iá»ƒm-tÃ­n-dá»¥ng)
2. [ğŸ‘¥ Dá»± Ã¡n 2: PhÃ¢n cá»¥m khÃ¡ch hÃ ng ngÃ¢n hÃ ng](#-dá»±-Ã¡n-2-phÃ¢n-cá»¥m-khÃ¡ch-hÃ ng-ngÃ¢n-hÃ ng)
3. [ğŸ’µ Dá»± Ã¡n 3: PhÃ¢n loáº¡i tiá»n tháº­t/giáº£](#-dá»±-Ã¡n-3-phÃ¢n-loáº¡i-tiá»n-tháº­tgiáº£)
4. [ğŸ’ Dá»± Ã¡n 4: Dá»± Ä‘oÃ¡n giÃ¡ kim cÆ°Æ¡ng](#-dá»±-Ã¡n-4-dá»±-Ä‘oÃ¡n-giÃ¡-kim-cÆ°Æ¡ng)
5. [ğŸ“ˆ Dá»± Ã¡n 5: Dá»± Ä‘oÃ¡n giÃ¡ cá»• phiáº¿u Uber](#-dá»±-Ã¡n-5-dá»±-Ä‘oÃ¡n-giÃ¡-cá»•-phiáº¿u-uber)
6. [ğŸŠ Dá»± Ã¡n 6: PhÃ¢n loáº¡i cháº¥t lÆ°á»£ng cam báº±ng CNN](#-dá»±-Ã¡n-6-phÃ¢n-loáº¡i-cháº¥t-lÆ°á»£ng-cam-báº±ng-cnn)

---

## ğŸ’³ Dá»± Ã¡n 1: PhÃ¢n loáº¡i Ä‘iá»ƒm tÃ­n dá»¥ng

### ğŸ¯ Giá»›i thiá»‡u
Dá»± Ã¡n nÃ y táº­p trung vÃ o viá»‡c xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh phÃ¢n loáº¡i Ä‘á»ƒ dá»± Ä‘oÃ¡n Ä‘iá»ƒm tÃ­n dá»¥ng cá»§a khÃ¡ch hÃ ng (Tá»‘t, KhÃ¡, KÃ©m) dá»±a trÃªn cÃ¡c thÃ´ng tin cÃ¡ nhÃ¢n vÃ  lá»‹ch sá»­ tÃ i chÃ­nh cá»§a há».

### âš™ï¸ Quy trÃ¬nh thá»±c hiá»‡n
1ï¸âƒ£ **Táº£i vÃ  khÃ¡m phÃ¡ dá»¯ liá»‡u**: Táº£i táº­p dá»¯ liá»‡u train vÃ  test, sau Ä‘Ã³ gá»™p láº¡i Ä‘á»ƒ thá»±c hiá»‡n tiá»n xá»­ lÃ½ Ä‘á»“ng bá»™.  
2ï¸âƒ£ **LÃ m sáº¡ch vÃ  tiá»n xá»­ lÃ½ dá»¯ liá»‡u**:  
- Thá»±c hiá»‡n lÃ m sáº¡ch vÄƒn báº£n Ä‘á»ƒ loáº¡i bá» cÃ¡c kÃ½ tá»± khÃ´ng cáº§n thiáº¿t.  
- Chuyá»ƒn Ä‘á»•i kiá»ƒu dá»¯ liá»‡u cá»§a cÃ¡c cá»™t cho phÃ¹ há»£p (vÃ­ dá»¥: ID, tuá»•i, thu nháº­p).  
    *   Xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ thiáº¿u (`NaN`) vÃ  cÃ¡c giÃ¡ trá»‹ Ä‘áº·c biá»‡t.  
    *   Xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ ngoáº¡i lá»‡ (outlier) báº±ng phÆ°Æ¡ng phÃ¡p IQR.  
    *   Äiá»n cÃ¡c giÃ¡ trá»‹ thiáº¿u cho cÃ¡c cá»™t sá»‘ báº±ng giÃ¡ trá»‹ trung bÃ¬nh vÃ  cÃ¡c cá»™t phÃ¢n loáº¡i báº±ng giÃ¡ trá»‹ mode.\   
3ï¸âƒ£ **Ká»¹ thuáº­t Ä‘áº·c trÆ°ng (Feature Engineering)**:  
    *   Táº¡o biáº¿n giáº£ (dummy variables) tá»« cÃ¡c cá»™t phÃ¢n loáº¡i cÃ³ chá»©a nhiá»u giÃ¡ trá»‹, vÃ­ dá»¥ nhÆ° `Type_of_Loan`.  
    *   Sá»­ dá»¥ng `OrdinalEncoder` Ä‘á»ƒ chuyá»ƒn Ä‘á»•i cÃ¡c cá»™t phÃ¢n loáº¡i cÃ²n láº¡i thÃ nh dáº¡ng sá»‘.  
4ï¸âƒ£ **Lá»±a chá»n vÃ  chuáº©n hÃ³a Ä‘áº·c trÆ°ng**:  
    *   Loáº¡i bá» cÃ¡c Ä‘áº·c trÆ°ng khÃ´ng cáº§n thiáº¿t dá»±a trÃªn phÃ¢n tÃ­ch.  
    *   Chuáº©n hÃ³a dá»¯ liá»‡u báº±ng `MinMaxScaler`.  
5ï¸âƒ£ **XÃ¢y dá»±ng vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh**:  
    *   PhÃ¢n chia dá»¯ liá»‡u thÃ nh táº­p huáº¥n luyá»‡n vÃ  táº­p xÃ¡c thá»±c.  
    *   Sá»­ dá»¥ng `GridSearchCV` Ä‘á»ƒ tÃ¬m cÃ¡c tham sá»‘ tá»‘i Æ°u cho mÃ´ hÃ¬nh `SVC`.  
    *   Huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh `SVC` vÃ  `KNeighborsClassifier`.  
6ï¸âƒ£ **ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh**:  
    *   ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh trÃªn táº­p xÃ¡c thá»±c báº±ng `classification_report` vÃ  `confusion_matrix`.  

### ğŸ† Káº¿t quáº£
> *(Pháº§n nÃ y Ä‘á»ƒ trá»‘ng Ä‘á»ƒ báº¡n tá»± Ä‘iá»n káº¿t quáº£ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh)*

### ğŸ’» CÃ´ng nghá»‡ sá»­ dá»¥ng
*   `pandas`, `numpy`
*   `matplotlib`, `seaborn`
*   `scikit-learn` (`LogisticRegression`, `KNeighborsClassifier`, `SVC`, `GridSearchCV`, `MinMaxScaler`)
*   `statsmodels`

---

## ğŸ‘¥ Dá»± Ã¡n 2: PhÃ¢n cá»¥m khÃ¡ch hÃ ng ngÃ¢n hÃ ng

### ğŸ¯ Giá»›i thiá»‡u
Dá»± Ã¡n nÃ y sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t phÃ¢n cá»¥m Ä‘á»ƒ phÃ¢n nhÃ³m khÃ¡ch hÃ ng cá»§a má»™t ngÃ¢n hÃ ng dá»±a trÃªn hÃ nh vi giao dá»‹ch vÃ  thÃ´ng tin nhÃ¢n kháº©u há»c. Má»¥c tiÃªu lÃ  Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ¡c phÃ¢n khÃºc khÃ¡ch hÃ ng khÃ¡c nhau nháº±m phá»¥c vá»¥ cho cÃ¡c chiáº¿n lÆ°á»£c kinh doanh.

### âš™ï¸ Quy trÃ¬nh thá»±c hiá»‡n
1ï¸âƒ£ **Táº£i vÃ  khÃ¡m phÃ¡ dá»¯ liá»‡u (EDA)**: Táº£i vÃ  kiá»ƒm tra thÃ´ng tin, dá»¯ liá»‡u thiáº¿u, dá»¯ liá»‡u trÃ¹ng láº·p.
2ï¸âƒ£ **LÃ m sáº¡ch dá»¯ liá»‡u**:
    *   Loáº¡i bá» cÃ¡c hÃ ng cÃ³ giÃ¡ trá»‹ thiáº¿u.
    *   Xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ khÃ´ng há»£p lá»‡ trong cá»™t giá»›i tÃ­nh.
    *   Chuyá»ƒn Ä‘á»•i cá»™t ngÃ y thÃ¡ng sang Ä‘á»‹nh dáº¡ng datetime vÃ  tÃ­nh toÃ¡n tuá»•i cá»§a khÃ¡ch hÃ ng.
3ï¸âƒ£ **PhÃ¢n tÃ­ch RFM (Recency, Frequency, Monetary)**:
    *   TÃ­nh toÃ¡n cÃ¡c giÃ¡ trá»‹ Recency, Frequency, vÃ  Monetary cho má»—i khÃ¡ch hÃ ng.
    *   Káº¿t há»£p cÃ¡c chá»‰ sá»‘ RFM vÃ o bá»™ dá»¯ liá»‡u chÃ­nh.
4ï¸âƒ£ **Trá»±c quan hÃ³a dá»¯ liá»‡u**: Sá»­ dá»¥ng `matplotlib` vÃ  `seaborn` Ä‘á»ƒ váº½ cÃ¡c biá»ƒu Ä‘á»“ phÃ¢n tÃ­ch (boxplot, histogram, bar chart) nháº±m hiá»ƒu rÃµ hÆ¡n vá» Ä‘áº·c Ä‘iá»ƒm cá»§a dá»¯ liá»‡u.
5ï¸âƒ£ **Tiá»n xá»­ lÃ½ nÃ¢ng cao**:
    *   Loáº¡i bá» cÃ¡c giÃ¡ trá»‹ ngoáº¡i lá»‡ (outlier).
    *   Xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ thiáº¿u cÃ²n láº¡i báº±ng cÃ¡ch Ä‘iá»n giÃ¡ trá»‹ trung vá»‹ (median) hoáº·c cÃ¡c phÆ°Æ¡ng phÃ¡p phÃ¹ há»£p khÃ¡c.
    *   Chuáº©n hÃ³a dá»¯ liá»‡u báº±ng `StandardScaler`.
6ï¸âƒ£ **XÃ¢y dá»±ng mÃ´ hÃ¬nh phÃ¢n cá»¥m**:
    *   Sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p Elbow vÃ  Silhouette Ä‘á»ƒ xÃ¡c Ä‘á»‹nh sá»‘ cá»¥m tá»‘i Æ°u cho **K-Means**.
    *   Ãp dá»¥ng thuáº­t toÃ¡n **K-Means** vÃ  **DBSCAN**.
    *   Sá»­ dá»¥ng **PCA** Ä‘á»ƒ giáº£m chiá»u dá»¯ liá»‡u vÃ  trá»±c quan hÃ³a cÃ¡c cá»¥m.
7ï¸âƒ£ **ÄÃ¡nh giÃ¡ vÃ  phÃ¢n tÃ­ch cá»¥m**:
    *   ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh báº±ng chá»‰ sá»‘ Silhouette.
    *   Trá»±c quan hÃ³a cÃ¡c cá»¥m trong khÃ´ng gian 3D (sá»­ dá»¥ng `plotly`) vÃ  phÃ¢n tÃ­ch Ä‘áº·c Ä‘iá»ƒm cá»§a tá»«ng cá»¥m.

### ğŸ† Káº¿t quáº£
> *(Pháº§n nÃ y Ä‘á»ƒ trá»‘ng Ä‘á»ƒ báº¡n tá»± Ä‘iá»n káº¿t quáº£ phÃ¢n tÃ­ch cÃ¡c cá»¥m khÃ¡ch hÃ ng)*

### ğŸ’» CÃ´ng nghá»‡ sá»­ dá»¥ng
*   `pandas`, `numpy`
*   `matplotlib`, `seaborn`, `plotly`
*   `scikit-learn` (`KMeans`, `DBSCAN`, `StandardScaler`, `PCA`)
*   `kneed`

---

## ğŸ’µ Dá»± Ã¡n 3: PhÃ¢n loáº¡i tiá»n tháº­t/giáº£

### ğŸ¯ Giá»›i thiá»‡u
Má»¥c tiÃªu cá»§a dá»± Ã¡n nÃ y lÃ  xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng phÃ¢n biá»‡t giá»¯a tiá»n tháº­t vÃ  tiá»n giáº£ dá»±a trÃªn cÃ¡c Ä‘áº·c trÆ°ng Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« hÃ¬nh áº£nh cá»§a tá» tiá»n.

### âš™ï¸ Quy trÃ¬nh thá»±c hiá»‡n
1ï¸âƒ£ **Táº£i vÃ  khÃ¡m phÃ¡ dá»¯ liá»‡u**: Táº£i dá»¯ liá»‡u vÃ  kiá»ƒm tra cÃ¡c thÃ´ng tin cÆ¡ báº£n, xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ thiáº¿u.
2ï¸âƒ£ **Tiá»n xá»­ lÃ½ dá»¯ liá»‡u**:
    *   Chuyá»ƒn Ä‘á»•i biáº¿n má»¥c tiÃªu `is_genuine` thÃ nh dáº¡ng sá»‘ (0/1).
    *   Kiá»ƒm tra sá»± máº¥t cÃ¢n báº±ng cá»§a dá»¯ liá»‡u vÃ  sá»­ dá»¥ng ká»¹ thuáº­t `RandomOverSampler` Ä‘á»ƒ cÃ¢n báº±ng láº¡i lá»›p thiá»ƒu sá»‘.
    *   Chuáº©n hÃ³a cÃ¡c Ä‘áº·c trÆ°ng báº±ng `MinMaxScaler` do cÃ³ sá»± chÃªnh lá»‡ch vá» thang Ä‘o.
3ï¸âƒ£ **XÃ¢y dá»±ng vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh**:
    *   PhÃ¢n chia dá»¯ liá»‡u thÃ nh táº­p huáº¥n luyá»‡n vÃ  táº­p kiá»ƒm tra.
    *   Sá»­ dá»¥ng `GridSearchCV` Ä‘á»ƒ tÃ¬m ra tham sá»‘ `n_neighbors` tá»‘t nháº¥t cho mÃ´ hÃ¬nh **KNN**.
    *   Sá»­ dá»¥ng `GridSearchCV` Ä‘á»ƒ tÃ¬m cÃ¡c tham sá»‘ tá»‘i Æ°u cho mÃ´ hÃ¬nh **Logistic Regression**.
4ï¸âƒ£ **ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh**:
    *   So sÃ¡nh hiá»‡u suáº¥t cá»§a hai mÃ´ hÃ¬nh dá»±a trÃªn `classification_report` vÃ  `confusion_matrix`.
    *   ÄÆ°a ra nháº­n xÃ©t vá» sá»± phÃ¹ há»£p cá»§a tá»«ng mÃ´ hÃ¬nh, Ä‘áº·c biá»‡t lÃ  kháº£ nÄƒng dá»± Ä‘oÃ¡n Ä‘Ãºng cÃ¡c trÆ°á»ng há»£p tiá»n giáº£ (False Negative).

### ğŸ† Káº¿t quáº£
> *(Pháº§n nÃ y Ä‘á»ƒ trá»‘ng Ä‘á»ƒ báº¡n tá»± Ä‘iá»n káº¿t quáº£ so sÃ¡nh vÃ  nháº­n xÃ©t mÃ´ hÃ¬nh)*

### ğŸ’» CÃ´ng nghá»‡ sá»­ dá»¥ng
*   `pandas`, `numpy`
*   `matplotlib`, `seaborn`
*   `scikit-learn` (`LogisticRegression`, `KNeighborsClassifier`, `GridSearchCV`, `MinMaxScaler`)
*   `imblearn` (`RandomOverSampler`)

---

## ğŸ’ Dá»± Ã¡n 4: Dá»± Ä‘oÃ¡n giÃ¡ kim cÆ°Æ¡ng

### ğŸ¯ Giá»›i thiá»‡u
Dá»± Ã¡n há»“i quy nÃ y nháº±m má»¥c Ä‘Ã­ch xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n giÃ¡ cá»§a kim cÆ°Æ¡ng dá»±a trÃªn cÃ¡c thuá»™c tÃ­nh váº­t lÃ½ cá»§a nÃ³ nhÆ° carat, cut, color, clarity, v.v.

### âš™ï¸ Quy trÃ¬nh thá»±c hiá»‡n
1ï¸âƒ£ **KhÃ¡m phÃ¡ dá»¯ liá»‡u (EDA)**:
    *   Táº£i vÃ  kiá»ƒm tra thÃ´ng tin chung cá»§a dá»¯ liá»‡u.
    *   PhÃ¢n tÃ­ch má»‘i tÆ°Æ¡ng quan giá»¯a cÃ¡c biáº¿n sá»‘.
    *   Trá»±c quan hÃ³a dá»¯ liá»‡u Ä‘á»ƒ phÃ¡t hiá»‡n outlier (sá»­ dá»¥ng boxplot) vÃ  kiá»ƒm tra phÃ¢n phá»‘i cá»§a cÃ¡c biáº¿n (sá»­ dá»¥ng histogram).
2ï¸âƒ£ **Tiá»n xá»­ lÃ½ dá»¯ liá»‡u**:
    *   Loáº¡i bá» cÃ¡c hÃ ng dá»¯ liá»‡u bá»‹ trÃ¹ng láº·p.
    *   Xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ khÃ´ng há»£p lá»‡ (vÃ­ dá»¥: kÃ­ch thÆ°á»›c x, y, z báº±ng 0).
    *   MÃ£ hÃ³a cÃ¡c biáº¿n phÃ¢n loáº¡i (`cut`, `color`, `clarity`) báº±ng `LabelEncoder`.
    *   Xá»­ lÃ½ outlier báº±ng cÃ¡ch thay tháº¿ chÃºng báº±ng giÃ¡ trá»‹ trung bÃ¬nh.
    *   Kiá»ƒm tra Ä‘a cá»™ng tuyáº¿n báº±ng há»‡ sá»‘ VIF.
3ï¸âƒ£ **Chuáº©n hÃ³a vÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh**:
    *   Chuáº©n hÃ³a dá»¯ liá»‡u báº±ng `MinMaxScaler`.
    *   PhÃ¢n chia dá»¯ liá»‡u thÃ nh cÃ¡c táº­p huáº¥n luyá»‡n vÃ  kiá»ƒm tra.
    *   XÃ¢y dá»±ng vÃ  huáº¥n luyá»‡n ba mÃ´ hÃ¬nh há»“i quy: **Linear Regression**, **Random Forest Regressor**, vÃ  **Decision Tree Regressor**.
4ï¸âƒ£ **ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh**:
    *   ÄÃ¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh báº±ng cÃ¡c Ä‘á»™ Ä‘o: RÂ² Score, Mean Absolute Error (MAE), vÃ  Root Mean Squared Error (RMSE).
    *   Sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p K-Fold Cross Validation Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ Ä‘á»™ á»•n Ä‘á»‹nh cá»§a mÃ´ hÃ¬nh.
    *   So sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh vÃ  chá»n ra mÃ´ hÃ¬nh tá»‘t nháº¥t.

### ğŸ† Káº¿t quáº£
> *(Pháº§n nÃ y Ä‘á»ƒ trá»‘ng Ä‘á»ƒ báº¡n tá»± Ä‘iá»n káº¿t quáº£ Ä‘Ã¡nh giÃ¡ vÃ  so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh)*

### ğŸ’» CÃ´ng nghá»‡ sá»­ dá»¥ng
*   `pandas`, `numpy`
*   `matplotlib`, `seaborn`
*   `scikit-learn` (`LinearRegression`, `RandomForestRegressor`, `DecisionTreeRegressor`, `LabelEncoder`, `MinMaxScaler`)
*   `statsmodels`

---

## ğŸ“ˆ Dá»± Ã¡n 5: Dá»± Ä‘oÃ¡n giÃ¡ cá»• phiáº¿u Uber

### ğŸ¯ Giá»›i thiá»‡u
Dá»± Ã¡n nÃ y phÃ¢n tÃ­ch vÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh chuá»—i thá»i gian Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡ Ä‘Ã³ng cá»­a cá»§a cá»• phiáº¿u Uber.

### âš™ï¸ Quy trÃ¬nh thá»±c hiá»‡n
1ï¸âƒ£ **Táº£i vÃ  khÃ¡m phÃ¡ dá»¯ liá»‡u**:
    *   Táº£i dá»¯ liá»‡u vÃ  chuyá»ƒn Ä‘á»•i cá»™t `Date` sang Ä‘á»‹nh dáº¡ng datetime.
    *   Trá»±c quan hÃ³a giÃ¡ cá»• phiáº¿u theo thá»i gian Ä‘á»ƒ nháº­n diá»‡n xu hÆ°á»›ng chung vÃ  cÃ¡c biáº¿n Ä‘á»™ng.
2ï¸âƒ£ **PhÃ¢n tÃ­ch chuá»—i thá»i gian**:
    *   PhÃ¢n rÃ£ chuá»—i thá»i gian (`seasonal_decompose`) Ä‘á»ƒ xem cÃ¡c thÃ nh pháº§n xu hÆ°á»›ng, mÃ¹a vá»¥ vÃ  pháº§n dÆ°.
    *   Sá»­ dá»¥ng biá»ƒu Ä‘á»“ ACF vÃ  PACF Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ¡c tham sá»‘ tá»± tÆ°Æ¡ng quan.
    *   Kiá»ƒm Ä‘á»‹nh tÃ­nh dá»«ng cá»§a chuá»—i thá»i gian báº±ng kiá»ƒm Ä‘á»‹nh Dickey-Fuller (ADF) vÃ  KPSS.
    *   Thá»±c hiá»‡n sai phÃ¢n Ä‘á»ƒ lÃ m cho chuá»—i thá»i gian trá»Ÿ nÃªn dá»«ng.
3ï¸âƒ£ **XÃ¢y dá»±ng mÃ´ hÃ¬nh ARIMA**:
    *   Sá»­ dá»¥ng `auto_arima` Ä‘á»ƒ tá»± Ä‘á»™ng tÃ¬m ra cÃ¡c tham sá»‘ (p, d, q) tá»‘i Æ°u cho mÃ´ hÃ¬nh ARIMA.
    *   Huáº¥n luyá»‡n mÃ´ hÃ¬nh ARIMA trÃªn táº­p huáº¥n luyá»‡n.
4ï¸âƒ£ **Dá»± Ä‘oÃ¡n vÃ  Ä‘Ã¡nh giÃ¡**:
    *   Dá»± Ä‘oÃ¡n giÃ¡ trá»‹ trÃªn táº­p kiá»ƒm tra.
    *   ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh báº±ng cÃ¡c chá»‰ sá»‘ RMSE vÃ  so sÃ¡nh vá»›i má»™t mÃ´ hÃ¬nh cÆ¡ sá»Ÿ (baseline).
    *   Trá»±c quan hÃ³a káº¿t quáº£ dá»± Ä‘oÃ¡n so vá»›i giÃ¡ trá»‹ thá»±c táº¿.

### ğŸ† Káº¿t quáº£
> *(Pháº§n nÃ y Ä‘á»ƒ trá»‘ng Ä‘á»ƒ báº¡n tá»± Ä‘iá»n káº¿t quáº£ dá»± Ä‘oÃ¡n vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh ARIMA)*

### ğŸ’» CÃ´ng nghá»‡ sá»­ dá»¥ng
*   `pandas`, `numpy`
*   `matplotlib`, `seaborn`
*   `statsmodels` (`ARIMA`, `seasonal_decompose`, `adfuller`, `kpss`)
*   `pmdarima` (`auto_arima`)

---

## ğŸŠ Dá»± Ã¡n 6: PhÃ¢n loáº¡i cháº¥t lÆ°á»£ng cam báº±ng CNN

### ğŸ¯ Giá»›i thiá»‡u
Dá»± Ã¡n nÃ y á»©ng dá»¥ng Máº¡ng NÆ¡-ron TÃ­ch cháº­p (CNN) Ä‘á»ƒ xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh phÃ¢n loáº¡i hÃ¬nh áº£nh, cÃ³ kháº£ nÄƒng phÃ¢n biá»‡t giá»¯a cam cháº¥t lÆ°á»£ng tá»‘t vÃ  cam cháº¥t lÆ°á»£ng kÃ©m.

### âš™ï¸ Quy trÃ¬nh thá»±c hiá»‡n
1ï¸âƒ£ **Chuáº©n bá»‹ dá»¯ liá»‡u**:
    *   Táº£i vÃ  sáº¯p xáº¿p dá»¯ liá»‡u hÃ¬nh áº£nh vÃ o cÃ¡c thÆ° má»¥c tÆ°Æ¡ng á»©ng vá»›i hai lá»›p: `Orange_bad` vÃ  `Orange_good`.
    *   Äá»c hÃ¬nh áº£nh, chuyá»ƒn Ä‘á»•i kÃ­ch thÆ°á»›c vá» (32x32), vÃ  chuáº©n hÃ³a giÃ¡ trá»‹ pixel.
    *   Táº¡o cÃ¡c táº­p dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  kiá»ƒm tra.
2ï¸âƒ£ **PhÃ¢n chia dá»¯ liá»‡u**:
    *   Sá»­ dá»¥ng `StratifiedShuffleSplit` Ä‘á»ƒ chia táº­p huáº¥n luyá»‡n thÃ nh táº­p huáº¥n luyá»‡n nhá» hÆ¡n vÃ  táº­p xÃ¡c thá»±c, Ä‘áº£m báº£o sá»± cÃ¢n báº±ng vá» tá»· lá»‡ cÃ¡c lá»›p.
3ï¸âƒ£ **XÃ¢y dá»±ng mÃ´ hÃ¬nh CNN**:
    *   Thiáº¿t káº¿ kiáº¿n trÃºc mÃ´ hÃ¬nh CNN bao gá»“m cÃ¡c lá»›p `Conv2D`, `MaxPooling2D`, `Flatten`, `Dense`, vÃ  `Dropout`.
    *   Lá»›p Ä‘áº§u ra sá»­ dá»¥ng hÃ m kÃ­ch hoáº¡t `sigmoid` cho bÃ i toÃ¡n phÃ¢n loáº¡i nhá»‹ phÃ¢n.
4ï¸âƒ£ **Huáº¥n luyá»‡n mÃ´ hÃ¬nh**:
    *   BiÃªn dá»‹ch mÃ´ hÃ¬nh vá»›i hÃ m máº¥t mÃ¡t `sparse_categorical_crossentropy` vÃ  trÃ¬nh tá»‘i Æ°u hÃ³a `Adam`.
    *   Sá»­ dá»¥ng `EarlyStopping` Ä‘á»ƒ trÃ¡nh overfitting.
    *   Huáº¥n luyá»‡n mÃ´ hÃ¬nh trÃªn táº­p dá»¯ liá»‡u Ä‘Ã£ chuáº©n bá»‹.
5ï¸âƒ£ **ÄÃ¡nh giÃ¡ vÃ  xuáº¥t káº¿t quáº£**:
    *   ÄÃ¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh trÃªn táº­p kiá»ƒm tra.
    *   Trá»±c quan hÃ³a lá»‹ch sá»­ huáº¥n luyá»‡n (Ä‘á»™ chÃ­nh xÃ¡c vÃ  máº¥t mÃ¡t).
    *   Dá»± Ä‘oÃ¡n nhÃ£n cho cÃ¡c áº£nh trong táº­p kiá»ƒm tra vÃ  lÆ°u káº¿t quáº£ vÃ o file CSV.

### ğŸ† Káº¿t quáº£
> *(Pháº§n nÃ y Ä‘á»ƒ trá»‘ng Ä‘á»ƒ báº¡n tá»± Ä‘iá»n Ä‘á»™ chÃ­nh xÃ¡c vÃ  cÃ¡c káº¿t quáº£ khÃ¡c cá»§a mÃ´ hÃ¬nh CNN)*

### ğŸ’» CÃ´ng nghá»‡ sá»­ dá»¥ng
*   `pandas`, `numpy`
*   `matplotlib`
*   `opencv-python`
*   `tensorflow`, `keras`
*   `scikit-learn`
